# Today I Learned

## Python

## Kaggle
* Play ground
  * Instant_Gratification
    * [solution_study](Kaggle/Instant_Gratification/solution_study.ipynb)
  * Binary Classification of Insurance Cross Selling
    * [study](Kaggle/Insurance_Cross_Selling/study.ipynb)
    * [copy_notebook1](Kaggle/Insurance_Cross_Selling/ps4e7_blender_of_generalization.ipynb)
  * Binary_Prediction_of_Poisonous_Mushrooms
    * [study_1](Kaggle/Binary_Prediction_of_Poisonous_Mushrooms/beginner-s-first-step.ipynb)
    * [study_2](Kaggle/Binary_Prediction_of_Poisonous_Mushrooms/beginner-s-first-step-2.ipynb)
  * ISIC_2024-Skin_Cancer_Detect_on_with_3D-TBP
    * [study_1](Kaggle/ISIC_2024-Skin_Cancer_Detect_on_with_3D-TBP/beginner.ipynb)
    * [study_2](https://drive.google.com/file/d/18wHSJqfKQ7a0TMTFnBpfFqg4DE3HrSYp/view?usp=sharing)
    * [study_3](https://drive.google.com/file/d/1nKSeC-wOPbxkvGGSyrYx_7yrmL8iTeIE/view?usp=sharing)
    * [study_4](https://drive.google.com/file/d/1B5grIvCSyHpokdYpEjb7x0rmy1lnfG1K/view?usp=sharing)
  
## Machine Learning
* [ensemble](Machine_Learning/ensemble/ensemble.md)
* [표준화 & 정규화](Machine_Learning/normal_standard/normal_standard.md)
* [ROC](Machine_Learning/ROC/ROC.md)
* [Polar 정리](Machine_Learning/Polar/Polar.md)
* [방사 기저 함수](Machine_Learning/RBF/RBF.md)
* [Stacking](Machine_Learning/Stacking/Stacking.md)
* [MCC](Machine_Learning/MCC/MCC.md)
* [범주형 데이터 전처리](Machine_Learning/Encoding/categorical.md)
* [XGboost](Machine_Learning/XGboost/XGboost.md)
* [LGBM](Machine_Learning/LGBM/LGBM.md)
  
* 핸드온머신러닝
    * [2장](Machine_Learning/HandsOn/2page.md)
    * [end_to_end](Machine_Learning/HandsOn/02_end_to_end.ipynb)
    * [classification](Machine_Learning/HandsOn/03_classification.ipynb)
    * [training_linear_models](Machine_Learning/HandsOn/04_training_linear_models.ipynb)
    * [support_vector_machines](Machine_Learning/HandsOn/05_support_vector_machines.ipynb)
    * [decision_trees](https://colab.research.google.com/drive/1wvMs2V3FnUyAhEAC3kCyaeUQ9hFPexVu?usp=sharing)
    * [ensemble_learning_and_random_forests](https://colab.research.google.com/drive/1O3RT4WM4Eg-TJJk9yfAwrwFMVoKBxyno?usp=sharing)
    * [dimensionality_reduction](https://colab.research.google.com/drive/1B80vpBLXVFVLvxCqOfgMfqRCZRXA7uep?usp=sharing)
    * [10장](Machine_Learning/HandsOn/10page.md)
  
* scikit-learn
    * [StratifiedKFold](scikit-learn/StratifiedKFold.md)
    * [make_pipeline](scikit-learn/make_pipeline.md)
    * [Pipeline](scikit-learn/Pipeline.md)
    * [ColumnTransformer](scikit-learn/ColumnTransformer.md)
    * [GridSearchCV](scikit-learn/GridSearchCV.md)
    * [SimpleImputer](scikit-learn/SimpleImputer.md)
    * [cross_val_score](scikit-learn/cross_validate_score.md)
    * [mutual_info_classif](scikit-learn/mutual_info_classif.md)
    * [LabelEncoder](scikit-learn/LabelEncoder.md)

## Deep Learning
* 자연어 처리와 컴퓨터비전 심층학습
  * [03 파이토치 기초]([scikit-learn/LabelEncoder.md](https://www.notion.so/03-0b20af3c9fef46c983bb60a39cff3ea3?pvs=4))

## 수학
* [산술 & 기하 & 조화 평균](math/mean.md)
* [자연로그](math/natural_logarithm.md)

## 메타코드m
출처 - 메타코드m
  * 데이터분석가 입문
    <br>
    기초문법은 pass
    
    전처리 부분
    * [3-01 pd.read_csv&Tabular_data&data_type](metacode/data_analyze/3-01_pd.read_csv&Tabular_data&data_type.ipynb)
    * [3-02 DataFrame_파악](metacode/data_analyze/3-02_DataFrame_파악.ipynb)
    * [3-03 columns&Series](metacode/data_analyze/3-03_columns&Series.ipynb)
    * [3-04 indexing&sorting](metacode/data_analyze/3_04_indexing&sorting.ipynb)
    * [3-05 filtering](metacode/data_analyze/3_05_filtering.ipynb)
    * [3-06 Dates&Times](metacode/data_analyze/3_06_Dates&Times.ipynb)
    * [3-07 groupby](metacode/data_analyze/3_07_groupby.ipynb)
    * [3-08 combine](metacode/data_analyze/3_08_combine.ipynb)
    * [3-09 pivot](metacode/data_analyze/3_09_pivot.ipynb)
    * [3-10 values&NA](metacode/data_analyze/3_10_values&NA.ipynb)
    * [3-11 마케팅_성과_자동화](metacode/data_analyze/3_99_마케팅_성과_자동화.ipynb)

    시각화 부분
    * [4-01 bar,tootip](metacode/data_analyze/4_01_bar,tootip.ipynb)
    * [4-02 line,_facet_row_col](metacode/data_analyze/4_02_line,_facet_row_col.ipynb)
    * [4-03 histogrem,add_vline_annotation,update_xaxes](metacode/data_analyze/4_03_histogrem,add_vline_annotation,update_xaxes.ipynb)
    * [4-04 pie](metacode/data_analyze/4_04_pie.ipynb)
    * [4-05 strip](metacode/data_analyze/4_05_strip.ipynb)
    * [4-06 scatter](metacode/data_analyze/4_06_scatter.ipynb)
    * [4-07 제품_포트폴리오_분석](metacode/data_analyze/4_99_제품_포트폴리오_분석.ipynb)
  
    마케팅 데이터 분석 및 지표 정의하기
    * [5-01 attribution](metacode/data_analyze/5_01_attribution.ipynb)
    * [5-02 conversion_window](metacode/data_analyze/5_02_conversion_window.ipynb)
    * [5-03 통합_데이터_분석](metacode/data_analyze/5_99_통합_데이터_분석과_마케팅_전략__EDA에서_광고_최적화까지.ipynb)

  * 미분과 최적화
    * [들어가며](metacode/differentiation/intro.md)
    * [미분 가능성](metacode/differentiation/differentiation_2.md)
    * [도함수 법칙](metacode/differentiation/differentiation_3.md)
    * [연쇄 법칙](metacode/differentiation/differentiation_4.md)
    * [미분과 최적화](metacode/differentiation/differentiation_5.md)
    * [고차 미분/ 다변수 함수의 미분](metacode/differentiation/differentiation_6.md)
    * [Gradient Descent 알아보기](metacode/differentiation/differentiation_7.md)
    * [Jacobian](metacode/differentiation/differentiation_8.md)
    * [Hessians](metacode/differentiation/differentiation_9.md)
    * [예제](metacode/differentiation/differentiation_10.md)
    * [딥러닝에서 chain rule](metacode/differentiation/differentiation_11.md)
    * [테일러 급수](metacode/differentiation/differentiation_12.md)
    * [최적화 들어가며](metacode/differentiation/differentiation_13.md)
    * [Gradient descent](metacode/differentiation/differentiation_14.md)
    * [step size 1](metacode/differentiation/differentiation_15.md)
    * [step size 2](metacode/differentiation/differentiation_16.md)
    * [Descent Direction](metacode/differentiation/differentiation_17.md)
  
  * 통계 기초
    * [들어가며](metacode/statistics/intro.md)
    * [중심](metacode/statistics/statics_1.md)
    * [산포](metacode/statistics/statics_2.md)
    * [형태](metacode/statistics/statics_3.md)
    * [상관](metacode/statistics/statics_4.md)
    * [확률의 정의](https://www.notion.so/89398275a2b540c0a8654c01f234d770?pvs=4)
    * [조건부 확률](https://www.notion.so/3847437bf39b4414a696fec66780c1e7?pvs=4)
    * [독립과 종속/베이즈 정리](https://www.notion.so/5076b3f349d2483a9a5951467226ba29?pvs=4)
    * [확률변수/이산확률변수/연속확률변수](https://www.notion.so/541a01bdc9dd4ef7b23e17036e6cf392?pvs=4)
    * [기대값](https://www.notion.so/e7cbf19c180b49f18a49cf7c02fff762?pvs=4)
    * [분산과 표준편차](https://www.notion.so/9343855725a54b84bf059aabc7c322f8?pvs=4)
    * [공분산과 상관계수](https://www.notion.so/7e4df82d33ea48c290ebe36c11ddd0fa?pvs=4)
    * [확률과 확률변수 예제풀이](https://www.notion.so/5bb050ac5b7e45dc813c9e45b72e8cfb?pvs=4)
    * [이항분포/포아송분포](https://www.notion.so/1cbea8052ee5407bbe6506f98a95d076?pvs=4)
    * [이산확률분포 예제풀이](https://www.notion.so/691b02518cb64d948a1360d4c8339324?pvs=4)
    * [확률밀도함수](https://www.notion.so/Uniform-Distribution-23de761856b54127a02e16b0567afe2e?pvs=4)
    * [정규분포](https://www.notion.so/af2e5a7fc9a943f798c83dcd1eede6dd?pvs=4)
    * [표본분포/중심극한정리](https://www.notion.so/b196115170a24ec99ac867a41cb4c15e?pvs=4)
    * [카이제곱분포](https://www.notion.so/e132ed84317a4961bbc1df34e4f811fd?pvs=4)
    * [t분포 및 F분포](https://www.notion.so/t-F-da69eb111cb14f349247441c53346ea3?pvs=4)
    * [연속확률분포 예제풀이](https://www.notion.so/eec671acd8444825bec3cfaa9ebb49ad?pvs=4)

  * 선형대수학
    * [들어가며](metacode/linear_algebra/intro.md)
    * [Dimension of Data](metacode/linear_algebra/algebra.md)
    * [벡터](metacode/linear_algebra/algebra_2.md)
    * [벡터 공간](metacode/linear_algebra/algebra_3.md)
    * [행렬](https://www.notion.so/ea7ed6a60eca4945aa1fb94bde05e34c?pvs=4)
    * [행렬의 성질](https://www.notion.so/409deb710bdd4448a440f21d52dad403?pvs=4)
    * [문제풀이 - 벡터의 덧셈과 곱셈](https://www.notion.so/2510a726af014eed9c8bcb486b3775ba?pvs=4)
    * [문제풀이 - 행렬과 벡터 사이의 곱](https://www.notion.so/c0aea3cf804747218b51f2da06fba521?pvs=4)
    * [문제풀이 - Linear combination의 기하학적 의미](https://www.notion.so/Linear-combination-11c11ddc85384fcc89f2e120862ed942?pvs=4)
    * [문제풀이 - 세 벡터의 조합](https://www.notion.so/9a6ea0bbef2443fba96bf2994a04e262?pvs=4)
    * [문제풀이 - 조건에 맞게 벡터 조합하기](https://www.notion.so/fd697c1da66247d1be91b1d778ab3b52?pvs=4)
    * [문제풀이 - 벡터의 기하학적 의미](https://www.notion.so/a0736206b5494de6aea08a7f50ba906c?pvs=4)
    * [문제풀이 - 두 벡터 간의 각도 구하기](https://www.notion.so/90dc6777ab454a7c9fd8b8a1c9a5ed01?pvs=4)
    * [문제풀이 - |u ⋅ v|≤||u||||v|| 공식 증명](https://www.notion.so/u-v-u-v-76269f4637d148fb9c43c07cd8660955?pvs=4)
    * [문제풀이 - 벡터의 직교](https://www.notion.so/ee4647e1654d4b1a826bb64516e22d35?pvs=4)
    * [행렬식](https://www.notion.so/Determinant-b07f087b86a1413fa16290a69f40d182?pvs=4)
    * [Dot prodcut](https://www.notion.so/Dot-product-fb0285d00c864e5a8f749de5e9a1fac9?pvs=4)
    * [문제풀이 - 벡터 연산의 최대, 최소 구하기](https://www.notion.so/689febbce4fc4aecb3f22e8b3a30d658?pvs=4)
    * [문제풀이 - Ax = b 알아보기](https://www.notion.so/Ax-b-1e19dbeb2d2d4164b58318113ce1495b?pvs=4)



  * 머신러닝 입문

  * 딥러닝 입문(pytorch)
    * 실습 1. Pytorch Fundamentals  - Tensor 다루기  
      <table>
        <td>
          <a href="https://colab.research.google.com/drive/148X9RXHy7wE4miGQTZYgB6F1zfgqOpXg#scrollTo=gtziUGnhjER0" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </td>
      </table>
    * [Neural Network - Matrix Multiplication](metacode\deep_learning\Neural_Network_3.md)
      <table>
        <td>
          <a href="https://colab.research.google.com/drive/1xXve14QL__6ECjuqQ9DPh8DSHZ4zD47G" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </td>
      </table>
    * Loss Function
      * [Loss Function](metacode\deep_learning\Neural_Network_4.md)
      * [Loss 최적화 - Gradient Descent](metacode\deep_learning\Neural_Network_5.md)
      * Loss 실습
      <table>
        <td>
          <a href="https://drive.google.com/file/d/1xXve14QL__6ECjuqQ9DPh8DSHZ4zD47G/view?usp=sharing" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </td>
      </table>
    * Regression
      * [Regression이란](metacode\deep_learning\Neural_Network_6.md)
      * [Linear Regression](metacode\deep_learning\Neural_Network_7.md)
      * Regression 실습
      <table>
        <td>
          <a href="https://drive.google.com/file/d/1_1W1Vdwc9Wb-nESMXI_upgef9-ywojeD/view?usp=sharing" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </td>
      </table>
    
    * CNN 
      * [Vision Classification](https://www.notion.so/Vision-Classification-ff5cd85b61db4aa9b23d4968fad7f664?pvs=4)
      * [Convolutional Neural Network(CNN) - part 1](https://www.notion.so/Convolutional-Neural-Network-CNN-part-1-06b84bd13eb44d18bf7b2520eca46bce?pvs=4)
      * [Convolutional Neural Network(CNN) - part 2](https://www.notion.so/Convolutional-Neural-Network-CNN-part-2-129dbdbc98384b8bb5fa8907c355f007?pvs=4)
      * CNN 실습
      <table>
        <td>
          <a href="https://drive.google.com/file/d/1NquOYHK9M9ENuW7XkYwJWwGI9u3oZt5C/view?usp=sharing" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </td>
      </table>

    * Time Series Model 
      * [Time Series Model](https://www.notion.so/Time-Series-Model-7d0cf11fad20419f960b7d8472b8e71d?pvs=4)
      * Time Series Model 실습
      <table>
        <td>
          <a href="https://drive.google.com/file/d/19LMw1AGpx23T7woec4-LTlhNxG3XCAXb/view?usp=sharing" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </td>
      </table>